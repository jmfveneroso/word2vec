\documentclass{article}
\usepackage{graphicx}
\usepackage[utf8]{inputenc}
\usepackage[T1]{fontenc}
\usepackage{pgfplots}
\usepackage{pgfplotstable} 
\usepackage{titlesec}
\usepackage{lipsum}
\usepackage{authblk}

\titleformat{\chapter}[display]{\normalfont\bfseries}{}{0pt}{\Large}

\renewcommand*\contentsname{Sumário}

\begin{document}

\title{Expansão de consultas com Word2Vec}
\author{João Mateus de Freitas Veneroso}
\affil{Departamento de Ciência da Computação da Universidade Federal de Minas Gerais}

\maketitle

\section{Introdução}

A sinonímia e a polissemia são duas propriedades complexas das linguagens naturais que tendem a prejudicar o
funcionamento das máquinas de busca. A sinonímia pode reduzir a revocação quando um termo utilizado na consulta
se faz presente somente na forma de um sinônimo em um documento relevante. Já a polissemia pode prejudicar a precisão
quando um único termo possui vários significados, ocasionando a revocação de documentos de conteúdo irrelevante
para a consulta. O problema de incompatibilidade entre os termos da consulta e os termos utilizados nos documentos
foi batizado de "Problema do Vocabulário" por Furnas et al. \cite{furnas1987}. Uma técnica simples e eficaz para atacar 
este problema é a expansão de consultas, que consiste basicamente em expandir a consulta com novos termos que capturem
melhor a intenção do usuário. Dentro desta perspectiva, existem vários métodos diferentes para realizar a expansão das
consultas, como explorado por Carpineto e Romano \cite{carpineto2012}. Uma abordagem competitiva da família dos modelos
de pseudo feedback de relevância é o Modelo de Relevância proposto por Lavrenko e Croft \cite{lavrenko2001}. Ele é 
baseado em modelos de linguagem e se sustenta na suposição de que tanto a consulta q como os primeiros documentos retornados R 
foram gerados por um modelo de linguagem desconhecido.
Assumindo independência entre os k termos da consulta $ q_i $ e os termos encontrados nos documentos, 
a seguinte estimativa para o modelo de linguagem pode ser construída:

\[
P(t, q_1, q_2, ..., q_k) = \sum_{d \in R} P(d)P(t|d) \prod_{i=1}^{k} p(q_i|d)
\]

O Modelo de Relevância vem sendo usado de forma abrangente e tem apresentado bons resultados. Em
contraponto, as técnicas de expansão automática de consultas também podem trazer desvantagens devido
ao fenômeno de "query drift" Mitra et al. \cite{mitra1998}. A inclusão de novos termos na consulta, principalmente
quando extraídos dos primeiros documentos retornados pela consulta original, pode ocasionar um aumento da 
especificidade em um sentido diferente da intenção latente do usuário. Para evitar a degeneração dos resultados
devido ao "query drift", é necessário garantir a proximidade semântica entre a necessidade de informação do usuário
e os termos da consulta expandida.

\section{Motivação}

Recentemente, desenvolvimentos na área de processamento de linguagem natural como o Word2Vec de Mikolov et al. 
\cite{mikolov2013} tem mostrado grande efetividade em modelar a proximidade semântica entre termos e expressões.
O Word2Vec utiliza informação contextual presente nas palavras que aparecem em torno de um termo para gerar
vetores que representam as relações semânticas em um espaço vetorial de dimensionalidade reduzida. A similaridade
entre os vetores gerados pelo Word2Vec pode ser utilizada para selecionar novos termos na expansão 
de consultas como mostrado por Kuzi et al. \cite{kuzi2016}. Além disso, os autores apresentaram um método para
realizar a integração dos termos selecionados com o pseudo feedback de relevância como apresentado em \cite{lavrenko2001}
para gerar resultados ainda mais satisfatórios.

No Word2Vec, as representações vetoriais dos termos são estáticas. Portanto, o contexto específico do discurso não é levado
em consideração quando se calculam as relações semânticas entre os termos. Enquanto esta perspectiva generalista
já se mostra bastante efetiva, Diaz et al. \cite{diaz2016} mostraram que vetores treinados em um conjunto restrito 
aos tópicos relevantes para a consulta conseguem capturar melhor as relações semânticas entre os termos.

Este artigo propõe uma metodologia de expansão de consultas por meio da utilização de \textit{word embeddings}. 
A técnica consiste em treinar vetores de termos com um conjunto de treino restrito à tópicos
relevantes à consulta e interpolá-los com vetores treinados globalmente. Termos com proximidade semântica 
aos vetores interpolados são escolhidos para promover a expansão das consultas com o intuito de melhorar os resultados 
de busca. A hipótese principal é que alguns tipos de consulta podem tirar proveito
de representações gerais de termos e outras de representações mais específicas. Por meio da interpolação entre os dois 
tipos de vetores procura-se obter um resultado melhor para a expansão de consultas.

\section{Modelo Base}

O ranking inicial dos documentos é produzido por meio de um modelo de linguagem de unigramas baseado no modelo de 
Ponte e Croft \cite{ponte1998} cuja representação normalmente assume a forma:

\[
P(q|d) = \prod_{i}p(q_i|d)
\]

onde $ q_i $ representa o termo i da consulta e d representa um documento. Os documentos são ranqueados com base na 
probabilidade do seu modelo de linguagem ter gerado a consulta $ P(q|d) $. É possível calcular o score dos documentos
com base no critério de máxima verossimilhança, no entanto, vamos utilizar o método de suavização de Dirichlet \cite{lafferty2001} 
que pode ser descrito pela fórmula:

\[
P(w|d) = \frac{c(w;d) + \mu P(w|C)}{\sum_w c(w;d) + \mu}
\]

onde queremos estimar $ P(w|d) $, a probabilidade do modelo de linguagem do documento d gerar a palavra w. Sendo que $ c(w;d) $ 
representa a contagem da palavra w no documento d, $ P(w|C) $ representa a probabilidade da palavra w na coleção completa C, ou seja, 
o modelo de linguagem da coleção, e $ \mu $ é um fator de normalização cujo valor, se não especificado, é igual a 50. Os métodos de 
suavização server para atribuir probabilidades não nulas às palavras que não aparecem no corpo dos documentos. Além disso, eles
possuem o bônus de incorporar termos equivalentes ao IDF e à normalização por tamanho de documentos na fórmula de cálculo,
melhorandos os resultados gerais. Outros métodos de suavização se diferenciam principalmente pela forma como incorporam o 
modelo de linguagem da coleção $ P(w|C) $ no cálculo.

Para realizar a expansão das consultas, utilizamos o modelo de relevância de Lavrenko et al. \cite{lavrenko2001}. Após realizarmos
a consulta com o modelo descrito anteriormente, os primeiros D documentos são selecionados (D = 50 para os experimentos realizados)
e utiliza-se a seguinte fórmula para calcular a probabilidade do modelo de relevância daqueles documentos RM ter gerado cada um dos 
termos presentes no subconjunto:

\[
P(t|RM) = \sum_{d \in D} P(t|d)P(q|d)
\]

onde $ P(t|d) $ é o modelo de linguagem com suavização de Dirichlet descrito anteriormente e $ P(q|d) $ é a "query likelihood"
normalizada. Os primeiros k termos são escolhidos para realizar a expansão da consulta com base em sua probabilidade $ P(t|RM) $
e a expansão da consulta é realizada com a seguinte expressão:

\[
P(t|RM,q) = (1-\lambda) P(t|RM) + \lambda P(t|q)
\]

sendo que o fator $ \lambda $ simplesmente considera qual será o peso da consulta original no ranking e qual será o peso dos 
termos novos na consulta expandida. Até aqui, este modelo representa a base para os nossos experimentos e será referido como
LM (Language Model).

\section{Integração com Word2Vec}

Esta seção discute como será feita a incorporação dos vetores de termos calculados com o Word2Vec no modelo base discutido na
seção anterior. A técnica discutida a seguir é uma adaptação do modelo com melhores resultados discutido em \cite{kuzi2016}. 
Primeiramente, o vetor da consulta é construído com base no somatório dos vetores de seus termos. Em \cite{mikolov2013}, Mikolov et al. 
mostraram que esta operação preserva com bom grau de acurácias as relações semânticas dos termos individuais. Após, termos construído
a centróide dos termos da consulta, queremos saber a proximidade dos demais termos da coleção com o vetor da consulta. Para isso, 
calculamos a proximidade de cada um dos vetores da coleção com base na expressão:

\[
Prox(\overrightarrow{t}, \overrightarrow{cent}) = exp(cos(\overrightarrow{t}, \overrightarrow{cent}))
\]

onde $ \overrightarrow{cent} $ representa o vetor da consulta e $ \overrightarrow{t} $ representa o vetor do termo. Finalmente,
os coeficientes de similaridade são normalizados de forma que a sua soma seja igual a 1, para que os coeficientes sejam convertidos
em probabilidades. Chamaremos estas probabilidades de $ P(t, Word2Vec) $. Agora, resta incorporar as probabilidades calculadas 
com o Word2Vec no nosso modelo base. Para isso, a equação do modelo de relevância se tornará:

\[
P(t|RM) = \alpha P(t, Word2Vec) + (1-\alpha) \sum_{d \in D} P(t|d)P(q|d)
\]

onde $ \alpha $ representa um fator de normalização que controlará o peso que vamos dar ao Word2Vec. Perceba que foi feita apenas 
uma combinação linear entre as probabilidades calculadas pelo Word2Vec e as probabilidades original do modelo de relevância. O
resto do modelo base permanece inalterado. É importante lembrar que na consulta expandida somente serão utilizados os termos que
apresentarem as k maiores probabilidades.

Por último, a integração entre os vetores gerais e específicos será feita por meio de uma combinação linear simples entre 
as probabilidades dos vetores.

\section{Experimentos}

Os experimentos foram realizados com base nos tópicos da TREC 2013 Web Track, que utiliza o dataset ClueWeb12. Os experimentos
foram feitos no subconjunto ClueWeb12-B13 do dataset original, que contém aproximadamente 50 milhões de páginas da web coletadas
em 2012. Os tópicos vão de 201 a 250. A implementação dos algoritmos utilizou o framework Indri (www.lemurproject.org). 

Os modelos testados foram o modelo base descrito na segunda seção (LM), o modelo com vetores gerais (W2V-GENERAL), o modelo
com vetores restritos aos tópicos das consultas (W2V-SPECIFIC) e o modelo que combina os dois anteriores (W2V-COMB). Os vetores
gerais foram treinados em uma subcoleção do Google News com aproximadamente 100 bilhões de palavras e são disponibilizados publicamente
em (https://code.google.com/archive/p/word2vec/). Os vetores específicos foram treinados em uma subcoleção da ClueWeb09-B13 contendo
apenas documentos relevantes aos tópicos das consultas 201-250.

\begin{center}
  \begin{table}
  \centering
  \begin{tabular}{ | r r r r r r r r | }
    \hline
    Modelo & MAP & P@5 & P@10 & P@15 & P@20 & P@30 & P@100 \\
    \hline
    LM & 0 & 0 & 0 & 0 & 0 & 0 & 0 \\
    W2V-GENERAL & 0 & 0 & 0 & 0 & 0 & 0 & 0 \\
    W2V-SPECIFIC & 0 & 0 & 0 & 0 & 0 & 0 & 0 \\
    W2V-COMB & 0 & 0 & 0 & 0 & 0 & 0 & 0 \\
    \hline
  \end{tabular}
  \caption{Resultados dos modelos de expansão de consultas}
  \label{tab:experiments}
  \end{table}
\end{center}

Em cada um dos experimentos, foi coletado o MAP (@1000) e a precisão P@5, P@10, P@15, P@20, P@30 e P@100. Os resultados estão descritos na 
tabela \ref{tab:experiments}.

\section{Conclusão}

O modelo proposto se mostrou melhor pior ou igual aos originais.

\bibliography{bibliography} 
\bibliographystyle{ieeetr}

\end{document}
